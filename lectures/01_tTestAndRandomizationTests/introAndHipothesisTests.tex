
\documentclass{beamer}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

% remove title and author from left panel
 \makeatletter
  \setbeamertemplate{sidebar \beamer@sidebarside}%{sidebar theme}
  {
    \beamer@tempdim=\beamer@sidebarwidth%
    \advance\beamer@tempdim by -6pt%
    \insertverticalnavigation{\beamer@sidebarwidth}%
    \vfill
    \ifx\beamer@sidebarside\beamer@lefttext%
    \else%
      \usebeamercolor{normal text}%
      \llap{\usebeamertemplate***{navigation symbols}\hskip0.1cm}%
      \vskip2pt%
    \fi%
  }%
\makeatother
% done remove title and author from left panel 

\hypersetup{colorlinks,citecolor=}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{natbib}
\usepackage{apalike}
\usepackage{comment}
% \usepackage{enumitem}
% \setlist[itemize]{topsep=0pt,before=\leavevmode\vspace{-1.5em}}
% \setlist[description]{style=nextline}
\usepackage{amsthm}
\usepackage{media9}
% \usepackage{multimedia}
\usepackage{hyperref}
\usepackage{tikz}
\tikzset{
     arrow/.style={-{Stealth[]}}
     }
\usetikzlibrary{positioning,arrows.meta}
\usetikzlibrary{shapes.geometric}

\setbeamertemplate{navigation symbols}{}%remove navigation symbols

\usepackage{setspace}

% \newtheorem{example}{Example}
% \setbeamertemplate{theorems}[numbered]

\newenvironment<>{example1}[1][Example 1]{%
  \setbeamercolor{block title}{fg=white,bg=cyan!75!black}%
  \begin{block}{#1}}{\end{block}}
\newenvironment<>{example2}[1][Example 2]{%
  \setbeamercolor{block title}{fg=white,bg=magenta!75!black}%
  \begin{block}{#1}}{\end{block}}

\newcounter{saveenumi}
\newcommand{\seti}{\setcounter{saveenumi}{\value{enumi}}}
\newcommand{\conti}{\setcounter{enumi}{\value{saveenumi}}}
\newcommand{\keepi}{\addtocounter{saveenumi}{-1}\setcounter{enumi}{\value{saveenumi}}}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{Introduction and hypothesis testing}

\author{Joaqu\'{i}n Rapela} % Your name
\institute[GCNU, UCL] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
Gatsby Computational Neuroscience Unit\\University College London % Your institution for the title page
}
\date{\today} % Date, can be changed to a custom date

\AtBeginSection[]
  {
     \begin{frame}<beamer>
     \frametitle{Contents}
         \tableofcontents[currentsection,hideallsubsections]
     \end{frame}
  }

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
\frametitle{Contents} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

\section{Course logistics}

\begin{frame}
\frametitle{Course logistics}
\end{frame}

\section{Statistical remarks}

\begin{frame}
    \frametitle{Working examples}

    \begin{example1}

        We know that the average running speed of control mice is 1~cm/sec. The
        sample average running speed of a cohort (N=100) of transgenic mice is
        $\bar{x}=2.7\,\text{cm/sec}$ and the sample standard deviation is
        $s=10~\text{cm/sec}$. Is the average running speed of mice in the
        transgenic cohort larger than that of control mice? Test with a
        confidence level $\alpha=0.01$.

    \end{example1}

\end{frame}

\begin{frame}
    \frametitle{Working examples}

    \begin{example2}

        We want to study the effect of a new drug on visual electrophysiology
        in humans. We know that the mean peak evoked response potential (ERP)
        over V1 during the first 200~ms after stimuli presentation is 2~mV. The
        sample mean peak ERP for a group of 50 medicated subjects is
        $\bar{x}=1.3\,\text{mV}$ and the sample standard deviation is
        $s=2.6~\text{mV}$. Does taking the new drug change the mean evoked ERP
        over V1? Provide your test p-value.

    \end{example2}

\end{frame}

\begin{frame}
\frametitle{Statistical remarks}

    \begin{enumerate}

        \item It is frequent in statistics to assume that observed data follows
            a given probability distribution. For example a:

            \begin{itemize}

                \item normal distribution with parameters mean $\mu$ and variance
                    $\sigma^2$, $\mathcal{N}(\mu,\sigma^2)$,

                \item Poisson distribution with expected rate parameter $\lambda$,
                    $\mathcal{P}(\lambda)$,

                \item Binomial distribution with number of observation parameter $n$
                    and with a success probability parameter $p$,
                    $\mathcal{B}(n,p)$.

            \end{itemize}
            \seti
    \end{enumerate}


\end{frame}

\begin{frame}
\frametitle{Statistical remarks}

    \begin{enumerate}

        \conti

        \item One branch of statistics, \textbf{estimation theory}, provides
            tools to estimate parameters of distributions from observations.

        \item Another branch of statistics, \textbf{hypothesis testing},
            provides tools to make statistically-informed decisions about
            values of parameters of distributions.

            \seti

    \end{enumerate}

\end{frame}

\begin{frame}
\frametitle{Statistical remarks}

    \begin{enumerate}[<+->]

        \conti

		\item To estimate parameters, or to make decisions about them, we use
observations, $x_1,\ldots,x_N$, that are \textbf{independent and identically
distributed}.

            \begin{example1}

				An observation is the average speed of a transgentic mouse
during an experimetal session. We assume that the average speeds of all
mice are samples from a common probability density function (identically
distributed) and that average speeds are independent across mice (independent).

            \end{example1}

            \begin{example2}

				An observation is the peak ERP of a medicated cohort
subject. We assume tha these ERPs are samples from the same probability density
function (identically distributed) and that these ERPs are independent across
subjects (independent).

            \end{example2}

            \seti

    \end{enumerate}

\end{frame}

\begin{frame}
\frametitle{Statistical remarks}

    \begin{enumerate}

        \conti

		\item A goal of statistics is to \textbf{infer properties of the
population} (e.g., the effect of the genetic manipulation on the running speed
of mice) from \textbf{properties of the sample} (e.g., the effect of the
manipulation on the running speed of the 100 sampled mice).

		\seti

    \end{enumerate}

\end{frame}

\begin{frame}
\frametitle{Statistical remarks}

	\begin{theorem}[Central Limit Theorem]
        Let $X_1,\ldots,X_N$ be independent and identically distributed random
        variables with mean $\mu$ and variance $\sigma^2$. Let $N$ be
        large. Then the sample mean
        \begin{align}
            \bar{X}=\frac{1}{N}\sum_{n=1}^NX_n\label{eq:sampleMean}
        \end{align}
        is distributed as $\bar{X}\sim\mathcal{N}(\mu,\frac{\sigma^2}{N})$.
	\end{theorem}

    Note: if $\sigma^2$ is unknown, we can estimate $\sigma^2$ with the sample
    variance $s^2=\frac{1}{N-1}\sum_{i=1}^N(x_i-\bar{x})^2$.  Then, for large
    $N$, $\bar{X}$ is approximately distributed as
    $\mathcal{N}(\mu,\frac{s^2}{N})$.

\end{frame}

\section{Hypothesis testing}

\begin{frame}
\frametitle{Main source}

    Chapter 9 ``Large-sample test of hypothesis'' and chapter 10 ``Inference from
    small samples'' from 

    \begin{center}
        \includegraphics[height=2.5in]{figures/mendenhall09-introductionToProbabilityAndStatistics-13edition_cover.pdf}
    \end{center}

\end{frame}

\begin{frame}
\frametitle{Null and alternative hypothesis}

    \begin{itemize}

        \item In hypothesis testing we work with a \textbf{null hypothesis},
            $\mathcal{H}_0$, and an \textbf{alternative hypothesis},
            $\mathcal{H}_a$, collect a sample of data $x_1,\ldots,x_N$, and
            test if this data provides sufficient statistical evidence in favor
            of the alternative hypothesis. If this happens we reject the null
            hypothesis.

        \item However, if the collected data does not provide sufficient
            statistical evicence in favor of the aternative hypothesis, we do
            not accept the null hypothesis, but we say that we failed to reject
            it.  \textbf{Hypothesis tests do not prove null hypothesis, they
            only provide statistical evidence to reject it, or fail to reject it.}

    \end{itemize}

	\onslide<2->{
	\begin{alertblock}

		The hypothesis that we aim to prove should be the alternative one.

	\end{alertblock}
	}

\end{frame}

\begin{frame}
\frametitle{Null and alternative hypothesis}

    \begin{example1}

        Is the average running speed of the transgenic cohort larger than that of the control cohort (i.e., 2~cm/sec)?

        \begin{description}

            \item[$\mathcal{H}_0$]: the average running speed of the trangenic cohort is 2~cm/sec.

            \item[$\mathcal{H}_a$]: the average running speed of the transgenic cohort is lager than 2~cm/sec.

        \end{description}

    \end{example1}

\end{frame}

\begin{frame}
\frametitle{Null and alternative hypothesis}

    \begin{example2}

		Is the mean peak visual ERP in the first 200~ms post stimuli different
in medicated than in control subjects (i.e., 2~mV)?

        \begin{description}

            \item[$\mathcal{H}_0$]: the mean peak visual ERP in medicated subjects is 2~mV.

            \item[$\mathcal{H}_a$]: the mean peak visual ERP in medicated subjects is different from 2~mV.

        \end{description}

    \end{example2}

\end{frame}

\begin{frame}
\frametitle{One- and two-tailed tests of hypothesis}

	\begin{description}

		\item[One-tailed test of hypothesis] directionality is suggested by the
alternative hypothesis. 

			\begin{example1}

				It is a one-tailed hypothesis test because the alternative
hypothesis requires that the mean speed of the transgenic mice be larger
(directionality) than that of the control mice.

			\end{example1}

		\onslide<2->{
		\item[Two-tailed test of hypothesis] directionality is not suggested by
the alterntive hypothesis.

			\begin{example2}

				 It is a two-tailed hypothesis test because the alternative
hypothesis requires that the visual ERP of the medicated subjects be different
(no directionality) than that of the control subjects.

			\end{example2}
		}
	\end{description}

\end{frame}

\begin{frame}
\frametitle{Test statistic and its sampling distribution}

    \begin{itemize}

        \item To perform a hypothesis test we propose a \textbf{test statistic}, a
            function of the sample data, like the sample mean in
            Eq.~\ref{eq:sampleMean}.

        \item Because the sample data is random, the test statistic is also
            random. To perform hypothesis tests we need to know the
            distribution of the test statistic, which is called the
            \textbf{sampling distribution}.

    \end{itemize}

\end{frame}

\begin{frame}
\frametitle{Test statistic and its sampling distribution for the working
    examples}

	Because both examples are tests for the population mean, $\mu$, because the
sample mean, $\bar{x}$, is a good estimator of the population mean, and because
both examples use a large number of samples, we will use the standardized
sample mean as our test statistic:

	\begin{align*}
		Z = \frac{\bar{X}-\mu_0}{s/\sqrt{N}}
	\end{align*}

	From the central limit theorem, we know the sampling distribution of this test statistic:

	\begin{align*}
		 Z\sim\mathcal{N}(0, 1)
	\end{align*}

\end{frame}

\begin{frame}
\frametitle{Rejection region}

    The \textbf{reject region} is a region of low probability under the null
    hypohesis, which is consitent with alternative hypothesis. The
    \textbf{non-reject region}, is a region of large probability under the null
    hypothesis, that is inconsistent with the alternative hypothesis.

\end{frame}

\begin{frame}
\frametitle{Rejection region}

	\begin{example1}

        We want to reject the null hypothesis that the average running speed of
        the tranenic mice equals 2~cm/sec if their sample mean speed is much
        larger than 2~cm/sec.  That is, we want to reject the null hypothesis
        if $z$ is large and positive. How large is large?

        \vspace{0.1in}

        To answer this question we define the \textbf{Type I error} of a test,
        as the error of rejecting the null hypothesis when it is valid. We also
        define the \textbf{significance level of the hypothesis test},
        $\alpha$, as the probability of Type I error admitted by the test.

        \vspace{0.1in}

        When designing a test we first decide on its significane level
        $\alpha$.  We then reject the null hypothesis if $z$ is larger than the
        value $z_\alpha$ that leaves $\alpha$ probability to its right, We call
        this value the \textbf{critical value} of the test (see figure on next
        slide).

	\end{example1}

\end{frame}

\begin{frame}
\frametitle{Rejection region}

	\begin{example1}

    	\begin{center}
        	\includegraphics[width=4in]{figures/right_tailed_test.png}
    	\end{center}
        \hfill Mendenhall et al., 2009

	\end{example1}

\end{frame}

\begin{frame}
\frametitle{Rejection region}

	\begin{example2}

        We want to reject the null hypothesis that the drug has not effect on
        the average visually evoked ERP if the sample mean visually evoked ERP
        of medicated subjects is much smaller or much larger than the mean
        visually evoked ERP of control subjects (2~mV).
        How small is small and how large is large?

        \vspace{0.1in}

        We will reject the null hypothesis if the standarized mean, $z$, is
        larger than the value $z_{\alpha/2}$ that leaves $\alpha/2$ probability
        to its right or smaller than the value $-z_{\alpha/2}$ that leaves
        $\alpha/2$ probability to its left (see figure on next slide).

	\end{example2}

\end{frame}

\begin{frame}
\frametitle{Rejection region}

	\begin{example1}

    	\begin{center}
        	\includegraphics[width=4in]{figures/two_tailed_test.png}
    	\end{center}
        \hfill Mendenhall et al., 2009

	\end{example1}

\end{frame}

\begin{frame}
\frametitle{Complete hypothesis test for example 1}

    \begin{example1}

        We know that the average running speed of control mice is 1~cm/sec. The
        sample average running speed of a cohort (N=100) of transgenic mice is
        $\bar{x}=2.7\,\text{cm/sec}$ and the sample standard deviation is
        $s=10~\text{cm/sec}$. Is the average running speed of mice in the
        transgenic cohort larger than that of control mice? Test with a
        confidence level $\alpha=0.01$.

        Relevant quantities: $\mu_0=1$, $N=100$, $\bar{x}=2.7$, $s=10$,
        $\alpha=0.01$.

        \begin{enumerate}

            \item identify the null hypothesis $H_0$: \textcolor{cyan}{the average running speed of the trangenic cohort is 2 cm/sec.}

            \item identify the alternative hypothesis $H_a$: \textcolor{cyan}{the average running speed of the trangenic cohort is larger than 2 cm/sec}.

            \item select a test statistic: \textcolor{cyan}{standarized sample mean $Z$}.

            \seti

        \end{enumerate}

	\end{example1}

\end{frame}

\begin{frame}
\frametitle{Complete hypothesis test for example 1}

    \begin{example1}

        \begin{enumerate}

            \conti

            \item set the rejection region: \textcolor{cyan}{right-tailed hypothesis test, with critical value $z_{0.01}=2.3263$}.

            \item calculate the observed value of the test statistic.

                \begin{align*}
                    \color{cyan}
                    z_\text{obs}=\frac{\bar{x}-\mu_0}{s/\sqrt{N}}=\frac{2.7-1}{10/\sqrt{100}}=1.7
                \end{align*}

            \item draw your conclusion: \textcolor{cyan}{$z_\text{obs}=1.7<2.3263=z_{0.01}$. Thus, there is not enough statistical evidence to reject the null hypothesis with a confidence level $\alpha=0.01$.}

        \end{enumerate}

        Would you reject the null hypothesis with  confidence level
        $\alpha=0.05$?

    \end{example1}

\end{frame}

\begin{frame}
\frametitle{p-value}

    We should not only report the conclusion ``reject/not reject'' of our
    hypothesis test. We should provide a measure of how much our data disagrees
    with the null hypothesis. One such measure is the p-value:

    \begin{definition}[p-value]

        The p-value (or observed significance level of a statistical test) is
        the probability that the test statistic is larger than the observed
        test statistic under the null hypothesis.

    \end{definition}

    \begin{small}
    Notes:

    \begin{itemize}

        \item small p-values indicate that the probability of obtaining a
            test statistic equal or larger than the observed one is small,
            indicating that our data support for the alternative hypothesis.

        \item large p-values suggest that our data does not support the
            alternative hypothesis.

    \end{itemize}
    \end{small}

\end{frame}

\begin{frame}
\frametitle{Rejection region}

    \begin{description}

        \item[Type I error]: reject the null hypothesis when it is true.

        \item[Type II error]: not reject the null hypothesis when the
            alternative one is true.

    \end{description}

    Some statistical tests are designed to constrain the probability of type I
    error, called the \emph{confidence level, $\alpha$} of the test. Most
    commonly $\alpha=0.05$.

    Other tests compute the observed value of the test statistic,
    $t_\text{obs}$ and calculate the probability that the test statistic is
    larger or equal than its observed value.  This probability is called the
    \textbf{p-value} of the test.

\end{frame}

\begin{frame}
\frametitle{Steps to perform a hypothesis test}

    We start assuming that we know the distribution of the experimental samples
    and we agree on a sample size $N$ (in
    Section~\ref{sec:selectionOfSamleSize} we discuss how to select and optimal
    sample size). We set the confidence level $\alpha$ of the test (i.e., the
    probability that the test statistic falls in the reject region given that
    the null hypothesis is valid).

    \begin{enumerate}

        \item collect an experimental sample $x_1,\ldots,x_N$.

        \item compute the value of the test statistic corresponding to the
    collected experimental sample (e.g., sample mean, Eq.~\ref{eq:sampleMean})

        \item calculate the sample statistic, $t_\text{obs}$.

        \item for testing based on confidence level:

            \begin{enumerate}[a]

                \item divide the space of all possible values of the test statistic
            on a reject and a non-reject regons at a confidence level $\alpha$.

                \item if the value of the test statistic falls in the reject
            region, reject the null hypothesis at a confidence $\alpha$. If it
            does not, do not reject the null hypothesis at this confidence.

            \end{enumerate}

        \item for testing based on p-value:

            \begin{enumerate}[a]

                \item calculate the p-value (i.e., the probability that the test
            statistic is larger than the observed one.

                \item reject the null hypothesis if the p-value is lower than the
            agreed confidence level $\alpha$, and do not reject it otherwise.

            \end{enumerate}

    \end{enumerate}

\end{frame}

\begin{frame}
\frametitle{Central limit theorem}

\end{frame}

\end{document}
