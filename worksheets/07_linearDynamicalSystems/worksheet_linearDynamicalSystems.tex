\documentclass[12pt]{article}

\usepackage{natbib}
\usepackage{apalike}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}

\usepackage[shortlabels]{enumitem}
\usepackage[colorlinks=]{hyperref}
\usepackage[margin=2cm]{geometry}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

\title{Worksheet: Linear Dynamical Systems}
\author{Joaquin Rapela and Aniruddh Galgali}

\begin{document}

\maketitle

\section{Sampling from a linear dynamical system}

Sample (i.e., simulate) observations from a linear dynamical system for
tracking.  Follow the equations on slide 16 of the
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/lectures/07_linearDynamicalSystems/LDS_SWCNeuroinf2024.pdf}{Linear
Dynamical Systems} lecture. That is, first sample an initial state
$\mathbf{x}_1$, then sample the remaining states
$\mathbf{x}_2,\ldots,\mathbf{x}_N$, and finally simple the observations
$\mathbf{y}_1,\ldots,\mathbf{y}_N$.

You may use the script
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/worksheets/07_linearDynamicalSystems/code/scripts/doSimulateTrajectoryDWPA.py}{doSimulateTrajectoryDWPA.py}
in the class repository, but you will need to complete a few missing parts in
function \texttt{simulatLDS} of
the module
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/worksheets/07_linearDynamicalSystems/code/src/simulation.py}{simulation.py} (Listing\ref{lst:simulateLDS}). First, in line 7 you need to draw all samples (N) of the observation noise. Second on line 15 you need to set the value of the state at time $n$. Finally, on line 16 you need to calculate the observation from the previously computed states and noise.

\begin{lstlisting}[caption={function \texttt{simulateLDS} in module \texttt{simulation.py}},label={lst:simulateLDS},language=python]
def simulateLDS(N, A, Q, H, R, mu0, P0):
    M = A.shape[0]
    P = H.shape[0]
    # sample state noise
    w = np.random.multivariate_normal(np.zeros(M), Q, N).T
    # sample measurement noise
    v = ...
    # sample initial state
    x0 = np.random.multivariate_normal(mu0, P0, 1).flatten()
    # sample states
    x = np.empty(shape=(M, N))
    y = np.empty(shape=(P, N))
    x[:, 0] = x0
    for n in range(1, N):
        x[:, n] = ...
    y = ...
    return x0, x, y
\end{lstlisting}

You should obtain a plot similar to that in Figure~\ref{fig:simulated_pos}.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=5in]{figures/simulated_pos.png}
		\label{fig:simulated_pos}
		\caption{Simulated observations and state position components
              using the Discrete Wiener Process Acceleration
              model~\citep[][Section 6.3.3]{barShalomEtAl04}.}
	\end{center}
\end{figure}

\section{Estimating kinematics of a foraging mouse}

Here we will estimate kinematics of a foraging mouse using a linear dynamical
system. Notes on how to design the matrices of a linear dynamical system for
kinematics inference appear
\href{https://github.com/joacorapela/lds_python/blob/master/docs/tracking/tracking.pdf}{here}.
The state of this linear dynamical system is six dimensional,
$\mathbf{x}\in\mathbb{R}^6$. $x[0]$ and $x[3]$, give the inferred
position components along the horizontal and vertical direction, respectively.
Similarly, $x[1]$ and $x[4]$, give inferred velocity components, and $x[2]$ and
$x[6]$, give the inferred acceleration components.

The video for this example was generously provided by the
Sainsbury Wellcome Centre Foraging Behaviour Working Group (2023). Aeon: An
open-source platform to study the neural basis of ethological behaviours over
naturalistic timescales, \url{https://doi.org/10.5281/zenodo.8413142}.

To infer mouse kinematics from this video you may want to use the script
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/worksheets/07_linearDynamicalSystems/code/scripts/doTrackMouse.py}{doTrackMouse.py}.
This script reads a video file and using the \href{https://opencv.org/}{OpenCV}
library, it estimates the center of mass
of the mouse and plots a red point at the position of this estimate.

The OpenCV estimates are noisy and sometimes they are not available due to occlusions.
Here we use the Kalman filter to remove this noise, to fill the
missing position values, and to estimate mouse velocities and accelerations.

At each sample time the Kalman filter provides the mean and covariance of the
posterior distribution of the state. The script plots a greeen point on the
video frame at the location of the mean position and a 95\% confidence ellipse
summarizing the variability of the position posterior distribution. The
brightness of this ellipse is modulated by the speed of the mouse, with a
darker ellipse for slower speeds and a brighter ellipse for higher speeds. Text
in the top left of the video prints the mouse speed and acceleration.
Figure~\ref{fig:trackedMouseWithKinematics} plots one example frame of the
video generated by the script. Click on the figure to obtain the full video.

\begin{figure}
	\begin{center}
		\href{https://www.gatsby.ucl.ac.uk/~rapela/neuroinformatics/2024/worksheets/linearDynamicalSystems/videos/FrameTop_2021-06-03T17-00-00_end001000.avi}{\includegraphics[width=5in]{figures/trackedMouseWithKinematics.png}}
		\label{fig:trackedMouseWithKinematics}

        \caption{Example frame of the video generated by the
        \href{https://github.com/joacorapela/neuroinformatics24/blob/master/worksheets/07_linearDynamicalSystems/code/scripts/doTrackMouse.py}{doTrackMouse.py}
        script. The OpenCV estimate of the mouse position is plotted in red,
        the Kalman filter estimateed mean of the position is plotted in green,
        and the 95\% confidence ellipse of the estimated position is drawn in
        green with brightness modulated by speed. Click on the figure to obtain
        the full video.}

	\end{center}
\end{figure}

To run this script you will need to complete two methods in the class
\texttt{OnlineKalmanFilter} in module
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/worksheets/07_linearDynamicalSystems/code/src/inference.py}{inference.py}.
%
First, you will need to complete the method \texttt{predict}
(Listing~\ref{lst:predict}). When calling this method \texttt{self.x} contains
the filtered mean at time t-1 (i.e., $\mu_{t-1|t-1}$ in slide 25 from the
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/lectures/07_linearDynamicalSystems/LDS_SWCNeuroinf2024.pdf}{LDS
lecture}). In line 8 of Listing~\ref{lst:predict} you need to set
\texttt{self.x} to the predicted mean at time t (i.e., $\mu_{t|t-1}$ in slide
25 from the
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/lectures/07_linearDynamicalSystems/LDS_SWCNeuroinf2024.pdf}{LDS
lecture}). Similarly, in line 9 of Listing~\ref{lst:predict} you need to set
the predicted covariance at time t (i.e., $P_{t|t-1}$ in slide 25 from the
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/lectures/07_linearDynamicalSystems/LDS_SWCNeuroinf2024.pdf}{LDS lecture}). 

\begin{lstlisting}[caption={method \texttt{predict} in class \texttt{OnlineKalmanFilter} in module \texttt{inference.py}},label={lst:predict},language=python]
    def predict(self):
        """Predicts the next state.

        :return: (mean, covariance): tuple containing the predicted mean and covariance matrix.

        """

        self.x = ...
        self.P = ...
        return self.x, self.P
\end{lstlisting}

Second, you will need to complete the method \texttt{update}
(Listing~\ref{lst:update}). When calling this method \texttt{self.x} contains
the filtered mean at time t-1 (i.e., $\mu_{t-1|t-1}$ in slide 25 from the
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/lectures/07_linearDynamicalSystems/LDS_SWCNeuroinf2024.pdf}{LDS
lecture}).
%
Lines 11 and 12 of Listing~\ref{lst:predict} calculate the observation
residuals ($y_t-H\mu_{t|t-1}$ in the expression of $\mu_{t|t}$ in slide 25 from
the
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/lectures/07_linearDynamicalSystems/LDS_SWCNeuroinf2024.pdf}{LDS
lecture}).
%
Lines 13-15 of Listing~\ref{lst:predict} calculate the inverse of the
observation residuals covariance matrix ($(HP_{t|t-1}H^\intercal+R)^{-1}$ in
the expression of $K_t$ in slide 25 from the
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/lectures/07_linearDynamicalSystems/LDS_SWCNeuroinf2024.pdf}{LDS
lecture}).
%
Line 16 computes Kalman gain ($K_t$ in slide 25 from the
\href{https://github.com/joacorapela/neuroinformatics24/blob/master/lectures/07_linearDynamicalSystems/LDS_SWCNeuroinf2024.pdf}{LDS
lecture}).
%
You will need to calculate the filtered mean in line 17 and the filtered
covariance in line 18.

\begin{lstlisting}[caption={method \texttt{update} in class \texttt{OnlineKalmanFilter} in module \texttt{inference.py}},label={lst:update},language=python]
    def update(self, y):
        """Calculates the filtered mean vector and covariance matrix.

        :param y: observation :math:`\in\Re^M`
        :return: (state, covariance): tuple containing the filtered mean vector and covariance matrix.

        """
        if y.ndim == 1:
            y = np.expand_dims(y, axis=1)
        if not np.isnan(y).any():
            pred_obs = self.H @ self.x
            residual = y - pred_obs
            Stmp = self.H @ self.P @ self.H.T + self.R
            S = (Stmp + Stmp.T) / 2
            Sinv = np.linalg.inv(S)
            K = self.P @ self.H.T @ Sinv
            self.x = ...
            self.P = ...
        return self.x, self.P

\end{lstlisting}

To run this script you need the OpenCV library. Installation instructions for
Linux, Mac and Windows can be found
\href{https://opencv.org/get-started/}{here}.

\section{Adjusting the parameters of the kinematics model (optional)}

You may have noticed that the filtered estimate of positions is sometimes
sluggish. This may happen because the parameters \texttt{sigma\_a},
\texttt{sigma\_x} and/or \texttt{sigma\_y} of the kinematics models are not set
to optimal values. Adjust these parameters to eliminate this sluggish tracking.
You may also want to automatically learn optimal parameter values using the
Expectation Maximization algorithm or by gradient ascent, as shown
\href{https://joacorapela.github.io/lds_python/auto_examples/tracking/plotEMvsGAcomparisonForagingMouse.html#sphx-glr-auto-examples-tracking-plotemvsgacomparisonforagingmouse-py}{here}.

\bibliographystyle{plainnat}
\bibliography{tracking}

\end{document}
